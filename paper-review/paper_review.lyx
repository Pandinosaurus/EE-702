#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family sfdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing other 0.95
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\rightmargin 2cm
\bottommargin 2cm
\secnumdepth 3
\tocdepth 5
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\bullet 0 0 9 -1
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
EE 702 Computer Vision | Paper Review
\end_layout

\begin_layout Author
Meet Pragnesh Shah | 13D070003 | meetshah1995@ee.iitb.ac.in
\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout

\series bold
Paper Title:
\series default
 Computing the Stereo Matching Cost with a Convolutional Neural Network
\end_layout

\begin_layout Plain Layout

\series bold
Authors: 
\series default
Yann LeCun, Jure Zbontar
\series bold
 
\end_layout

\begin_layout Plain Layout

\series bold
Conference:
\series default
 CVPR 2015 [ pdf : http://arxiv.org/abs/1409.4326 ] [code : https://github.com/jzbo
ntar/mc-cnn ]
\end_layout

\end_inset


\end_layout

\begin_layout Section
Abstract
\end_layout

\begin_layout Standard
We present a method for extracting depth information from a rectified image
 pair.
 We train a convolutional neural network to predict how well two image patches
 match and use it to compute the stereo matching cost.
 The cost is refined by cross-based cost aggregation and semiglobal matching,
 followed by a left-right consistency check to eliminate errors in the occluded
 regions.
 Our stereo method achieves an error rate of 
\series bold
2.61 %
\series default
 on the KITTI stereo dataset and is currently (August 2014) the top performing
 method on this dataset.
\end_layout

\begin_layout Section
Brief Explanation
\end_layout

\begin_layout Standard
The method presented by the authors leverages convolutional neural networks
 [CNN] for cost computation of the image patches for consequent stereo matching.
 It is currently the 
\series bold
top performer 
\series default
on the 
\series bold
KITTI stereo dataset
\series default
.
 The method works as follows: 
\end_layout

\begin_layout Itemize
A dataset is initially generated consisting of 9x9 patches of images from
 the left and right images such as 
\begin_inset ERT
status open

\begin_layout Plain Layout

$I_
\backslash
textrm{left}(i,j)$
\end_layout

\end_inset

 and 
\begin_inset ERT
status open

\begin_layout Plain Layout

$I_
\backslash
textrm{right}(i-d+offset,j)$
\end_layout

\end_inset

 where 
\begin_inset ERT
status open

\begin_layout Plain Layout

$d$
\end_layout

\end_inset

 is the known disparity and the 
\begin_inset ERT
status open

\begin_layout Plain Layout

$offset$
\end_layout

\end_inset

 is a 
\series bold
signed 
\series default
hyperparameter of the system.
 This training set is later used to train a 8 layered CNN.
 The CNN output is a intermediate cost of the system.
\end_layout

\begin_layout Itemize
The cost is aggregated using a cross based method, wherein a cross [] is
 defined for each pixel such that the arms of cross extend in all 4 directions
 of the pixel until the sum of absolute difference in intensities exceeds
 a threshold or the maximum arm length (predefined hyperparameter) is exceeded.
 The collection of all pixels in the crosses of neighbouring pixels is used
 to aggregate the cost for a single pixel.
 The cost is then calculated iteratively for 4 iterations to give a intermediate
 cost 
\begin_inset ERT
status open

\begin_layout Plain Layout

$C_
\backslash
textrm{CBCA}$
\end_layout

\end_inset

.
\end_layout

\begin_layout Itemize
Semi-global matching is then performed on the cost obtained above in which
 the cost is penalized differentially (using hyperparameters) for different
 local changes in disparities, this ensures that the jumps in disparities
 coincide with edges.
 This energy function is minimized in 4 directions and the arg min of the
 costs in all directions is taken as the output disparity map.
 Later left right consistency checks are performed to identify the mismatches
 and occlusions.
 The occlusions and mismatches are then handled by averaging and interpolating
 over windows of other pixels with no occlusions.
\end_layout

\begin_layout Itemize
Lastly sub-pixel enhancement is performed using quadratic curve fitting
 and then a median and bilateral filter is applied to the output disparity
 map to get the final disparity map 
\begin_inset ERT
status open

\begin_layout Plain Layout

$D_
\backslash
textrm{final}$
\end_layout

\end_inset

.
\end_layout

\begin_layout Section
Critique
\end_layout

\begin_layout Subsection
Merits 
\end_layout

\begin_layout Itemize
This method generates a cross (over which cost is aggregated) which is adaptive
 (in terms of size) to each pixel and the window is larger for neighbourhoods
 with similar disparities and vice versa.
 Hence this cross-based cost aggregation helps in reducing formation of
 textures (disparity confusion) at such pixels which is observed in naive
 stereo algorithms.
\end_layout

\begin_layout Itemize
This method also incorporates textures that may arise due to directional
 gradients (edges) by using semi global matching in 4 directions which ensures
 that the cost is penalized for large differences in disparities for neighbourin
g pixels.
 Hence it ensures that jumps in disparities coincide with the edges in the
 images.
\end_layout

\begin_layout Itemize
A quadratic neighbourhood based curve fitting using sub-pixel enhancement
 helps in regaining the resolution lost in averaging.
\end_layout

\begin_layout Itemize
A very fine attempt with very little computational overhead to remove occlusions
, disparity confusion (at edges) and mismatches using left right consistency,
 refinement, filtering
\series bold
 
\series default
and interpolation.
 
\end_layout

\begin_layout Itemize
The cost calculation is iterative and hence the
\series bold
 
\series default
costs have smoother gradients and hence give rise to a smoother disparity
 map with lesser spikes.
\end_layout

\begin_layout Itemize
The matching accuracy increases with increase in training sets as shown
 by the author which is a positive indicator of the robustness of the CNN
 learning architecture.
\end_layout

\begin_layout Itemize
This method effectively uses variants of several different techniques used
 by references in order to eliminate textures, occlusions and mismatches
 from the final disparity map.
\end_layout

\begin_layout Subsection
Demerits
\end_layout

\begin_layout Itemize
The author explicitly mentions that the CNN architecture changes with the
 dataset.
 The architecture is thus not generic enough to learn features from some
 input and effectively use them on a wide spectrum of input images.
 This implies that the training of the network (
\begin_inset ERT
status open

\begin_layout Plain Layout

$~5hrs$
\end_layout

\end_inset

) has to be done every time the input type changes.
 
\end_layout

\begin_layout Itemize
The implementation and methods suggested by the authors is not a 
\series bold
plug-and-play
\series default
 method and needs to be trained (supervised learning) on a dataset with
 known ground truths before it can be used.
 Further more the performance of the architecture on a set of input other
 than the training input is yet to be explored.
\end_layout

\begin_layout Itemize
The network may be prone to over-fitting (general problem with Convnets)
 and might learn rot learn the features specific to the training dataset
 and might not perform with similar accuracy on other datasets.
\end_layout

\begin_layout Itemize
This method involves too many parameters and hyperparameters for a relatively
 simple problem which are dependent on the dataset and hence parameter tuning
 is required every time the dataset type changes.
\end_layout

\begin_layout Itemize
The training and testing was done on the GPUs taking 
\series bold

\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
textbf{~100s}$
\end_layout

\end_inset


\series default
 per image pair.
 This method thus is not a practical method and the author is yet to explore
 ways to reduce the runtime in order to make it practically feasible.
\end_layout

\begin_layout Itemize
The increment in accuracy was very little when compared to the large amount
 of time taken.
 Other methods with competitive and similar accuracy perform the same task
 with significantly lesser time.
\end_layout

\begin_layout Itemize
Last but not the least, the method and all it's accuracy gains are obtained
 on grayscale images.
 The experiments on a RBG dataset are yet to be done.
 Given the 
\begin_inset ERT
status open

\begin_layout Plain Layout

$3x$
\end_layout

\end_inset

 amount of data in RGB images, the time taken and accuracy gains might also
 suffer.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "hirschmuller:pami"

\end_inset

 Hirschmuller, H.
 (2008).
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newblock
\end_layout

\end_inset

 Stereo processing by semiglobal matching and mutual information.
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newblock
\end_layout

\end_inset

 Pattern Analysis and Machine Intelligence,
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newblock
\end_layout

\end_inset

 IEEE 2008.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "yamaguchi:eccv"

\end_inset

Yamaguchi, K., McAllester, D., and Urtasun, R.
 (2014).
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newblock
\end_layout

\end_inset

 Efficient joint segmentation, occlusion labeling, stereo and flow estimation.
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newblock
\end_layout

\end_inset

 In Computer Vision–ECCV 2014.
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newblock
\end_layout

\end_inset

 Springer.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "zhang:csvt"

\end_inset

Zhang, K., Lu, J., and Lafruit, G.
 (2009).
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newblock
\end_layout

\end_inset

 Cross-based local stereo matching using orthogonal integral images.
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newblock
\end_layout

\end_inset

 Circuits and Systems for Video Technology,
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
newblock
\end_layout

\end_inset

 IEEE Transactions
\end_layout

\end_body
\end_document
